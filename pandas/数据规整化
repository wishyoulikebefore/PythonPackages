合并数据集
merge：根据一个或多个键将不同DataFrame中的行连接起来
join:
concat：沿着一条轴将多个对象堆叠到一起

DataFrame合并
merge(left, right, how='inner', on=None, left_on=None, right_on=None, left_index=False, right_index=False, sort=False, suffixes=('_x', '_y'), copy=True, indicator=False)
--------------------------------------------------------------------
how : {'left', 'right', 'outer', 'inner'}, default 'inner'
#outer：并集     inner：交集     left/right：类似于SQL的join
on：用于连接的列名，默认为交集
left_on/right_on：指定左右DataFrame中用作连接键的列
left_index/right_index：布尔值
suffixes：用于追加到重叠列名的末尾
indicator=True：可以注明每行数据的来源
--------------------------------------------------------------------

取键的交集
>>> pd.merge(df1,df2,on="key")                
取键的并集
>>> pd.merge(df1,df2,on="key",how="outer")     
对象列名不同，进行指定
>>> pd.merge(df1,df2,left_on="lkey",right_on="rkey")

多对多的合并：产生行的笛卡尔集
In [12]: df1 = DataFrame({"key":["b","b","a","c","a","b"],"data1":range(6)})
In [13]: df2 = DataFrame({"key":["a","b","a","b","d"],"data2":range(5)})
In [14]: pd.merge(df1,df2,on="key",how="left")
Out[14]: 
    data1 key  data2
0       0   b    1.0
1       0   b    3.0
2       1   b    1.0
3       1   b    3.0
4       2   a    0.0
5       2   a    2.0
6       3   c    NaN
7       4   a    0.0
8       4   a    2.0
9       5   b    1.0
10      5   b    3.0

索引上的合并
利用left_index=True或者right_index=True
>>> pd.merge(left1,right1,left_on="key",right_index=True)
同时合并双方的索引
>>> pd.merge(left2,right2,how="outer",left_index=True,right_index=True)

使用join(other, on=None, how='left', lsuffix='', rsuffix='', sort=False)
#默认索引合并，当左右列名有重复时，需用lsuffix和rsuffix指定
>>> left2.join(right2)

轴向连接
numpy：concatenate
In [27]: arr = np.arange(12).reshape(4,3)
In [28]: np.concatenate([arr,arr],axis=1)
Out[28]: 
array([[ 0,  1,  2,  0,  1,  2],
       [ 3,  4,  5,  3,  4,  5],
       [ 6,  7,  8,  6,  7,  8],
[ 9, 10, 11,  9, 10, 11]])

pandas：concat函数
concat(objs, axis=0, join='outer', join_axes=None, ignore_index=False, keys=None, levels=None, names=None, verify_integrity=False, copy=True)
-----------------------------------------------------------
join : {'inner', 'outer'}, default 'outer'
join_axes：指明使用的索引
keys：列表，注明合并后数组来源
names：用于创建分层级别的名称
ignore_index=True：不保留连接轴上的索引，产生一组新索引
-----------------------------------------------------------
>>>s1 = Series([0,1],index=["a","b"])
>>>s2 = Series([2,3,4],index=["c","d","e"])
>>>pd.concat([s1,s2])
a    0
b    1
c    2
d    3
e    4
#通过axis=1进行横向合并

合并重叠数据
基于np.where
或者combine_first()：组合Series值，优先第一个Series值，非NA值优先
In [52]: df1 = DataFrame([[1,np.nan]])
In [53]: df2 = DataFrame([[3,4]])
In [54]: df1.combine_first(df2)
Out[54]: 
   0    1
0  1  4.0

重塑和轴向旋转
重塑层次化索引
stack：列转行
unstack：行转列
 
#默认情况下，unstack操作的是最内层

pivot(index=None, columns=None, values=None)
#透视，列转行
#values为填充DataFrame数据列的列名
In [4]: frame = pd.DataFrame({'foo': ['one','one','one','two','two','two'],
   ...:                        'bar': ['A', 'B', 'C', 'A', 'B', 'C'],
   ...:                        'baz': [1, 2, 3, 4, 5, 6]})
In [6]: frame.pivot(index="foo",columns="bar",values="baz")
Out[6]: 
bar  A  B  C
foo         
one  1  2  3
two  4  5  6
注：pivot相当于：set_index创建层次化索引，再用unstack重塑

透视表：pivot_table()
#根据一个或多个键对数据进行聚合，并根据行和列上的分组键将数据分配到各个矩形区域
pivot_table(data, values=None, index=None, columns=None, aggfunc='mean', fill_value=Non)
In [16]: tips = pd.read_csv("ch08/tips.csv")
In [17]: tips.head()
Out[17]:
   total_bill   tip     sex smoker  day    time  size
0       16.99  1.01  Female     No  Sun  Dinner     2
1       10.34  1.66    Male     No  Sun  Dinner     3
2       21.01  3.50    Male     No  Sun  Dinner     3
3       23.68  3.31    Male     No  Sun  Dinner     2
4       24.59  3.61  Female     No  Sun  Dinner     4

In [20]: tips.pivot_table(["tip","size"],index=["sex","day"],columns="smoker")
 
#传入margins=True添加行和列的小计和总计
In [21]: tips.pivot_table(["tip","size"],index=["sex","day"],columns="smoker",margins=True)
 
#传入其它函数
In [25]: tips.pivot_table("tip",index=["sex","day"],columns="smoker",aggfunc="count",margins=True)
 

melt(frame, id_vars=None, value_vars=None, var_name=None, value_name='value', col_level=None)
-----------------------------------------------------------------------------------------------------------
逆透视
#id_vars:不需要被转换的列名。
#value_vars:需要转换的列名；None对应其它列都需要被转化
#var_name：转化列的列名
#value_name：转化列对应的值
最终生成的dataframe：行数 = len(df)*len(value_vars)
-----------------------------------------------------------------------------------------------------------
 
交叉表：crosstab
#计算分组频率的特殊透视表
crosstab(index, columns, values=None, rownames=None, colnames=None, aggfunc=None, margins=False, margins_name='All', dropna=True, normalize=False)

In [30]: pd.crosstab([tips.time,tips.day],tips.smoker,margins=True)
 
#也可以使用pivot_table，但是不如crosstab方便

数据转化
移除重复数据
利用duplicated()返回布尔型Series
#筛选出非重复行：df[df.duplicated(["first_name","last_name"])==False]
#keep='last'可以让系统从后向前开始筛查，索引小的重复行会返回 'True'

利用drop_duplicates()
In [36]: data = DataFrame({"k1":["one"]*3+["two"]*4,"k2":[1,1,2,3,3,4,4]})
In [40]: data.drop_duplicates()
Out[40]: 
    k1  k2
0  one   1
2  one   2
3  two   3
5  two   4
指定部分列进行判断，保留第一个出现的值组合
In [41]: data.drop_duplicates(["k1"],inplace=True)
Out[41]: 
    k1  k2
0  one   1
3  two   3

离散化和面元划分
将人员数据划分为不同年龄组
In [53]: ages = [20,22,25,27,21,23,27,31,61,45,41,32]
In [54]: bins = [18,25,35,60,100]
设置右区间为开
In [60]: pd.cut(ages,bins,right=False)
Out[60]: 
[[18, 25), [18, 25), [25, 35), [25, 35), [18, 25), ..., [25, 35), [60, 100), [35, 60), [35, 60), [25, 35)]
Length: 12
Categories (4, interval[int64]): [[18, 25] < [25, 35] < [35, 60] < [60, 100]]
设置面元名称
In [61]: group_names = ["Youth","YoungAdult","MiddleAged","Senior"]
In [62]: pd.cut(ages,bins,labels=group_names)
Out[62]: 
[Youth, Youth, Youth, YoungAdult, Youth, ..., YoungAdult, Senior, MiddleAged, MiddleAged, YoungAdult]
Length: 12
Categories (4, object): [Youth < YoungAdult < MiddleAged < Senior]

qcut(data,4)：可以将样本按四分位数等分

检测和过滤异常值
利用布尔型DataFrame和any方法
In [64]: data = DataFrame(np.random.randn(1000,4))
In [65]: data[(np.abs(data)>3).any(1)]
Out[65]: 
            0         1         2         3
5   -0.539741  0.476985  3.248944 -1.021228
97  -0.774363  0.552936  0.106061  3.927528
102 -0.655054 -0.565230  3.176873  0.959533
305 -2.315555  0.457246 -0.025907 -3.399312
324  0.050188  1.951312  3.260383  0.963301
400  0.146326  0.508391 -0.196713 -3.745356
499 -0.293333 -0.242459 -3.056990  1.918403
523 -3.428254 -0.296336 -0.439938 -0.867165
586  0.275144  1.179227 -3.184377  1.369891
808 -0.362528 -3.548824  1.553205 -2.186301
900  3.366626 -2.372214  0.851010  1.332846

排列和随机采样
In [66]: frame = DataFrame(np.arange(5*4).reshape(5,4))
利用np.random.permutation：随机重排列
In [67]: sample = np.random.permutation(5)
In [68]: sample
Out[68]: array([1, 0, 2, 3, 4])

In [69]: frame.take(sample)
Out[69]: 
    0   1   2   3
1   4   5   6   7
0   0   1   2   3
2   8   9  10  11
3  12  13  14  15
4  16  17  18  19
