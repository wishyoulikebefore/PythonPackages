合并数据集
merge：根据一个或多个键将不同DataFrame中的行连接起来
concat：沿着一条轴将多个对象堆叠到一起

数据库风格的DataFrame合并
merge(left, right, how='inner', on=None, left_on=None, right_on=None, 
      left_index=False, right_index=False, sort=False, suffixes=('_x', '_y'), copy=True, indicator=False)

how : {'left', 'right', 'outer', 'inner'}, default 'inner'
#outer：并集  inner：交集  left/right：类似于SQL的join
on：用于连接的列名，默认为交集
left_on/right_on：指定左右DataFrame中用作连接键的列
left_index：布尔值
suffixes：字符串值元组，用于追加到重叠列名的末尾

In [4]: df1 = DataFrame({"key":["b","b","a","c","a","a","b"],"data1":range(7)})
In [5]: df2 = DataFrame({"key":["a","b","d"],"data2":range(3)})
In [6]: pd.merge(df1,df2,on="key")
Out[6]:
   data1 key  data2
0      0   b      1
1      1   b      1
2      6   b      1
3      2   a      0
4      4   a      0
5      5   a      0

In [8]: pd.merge(df1,df2,on="key",how="outer")     #取键的并集
Out[8]: 
   data1 key  data2
0    0.0   b    1.0
1    1.0   b    1.0
2    6.0   b    1.0
3    2.0   a    0.0
4    4.0   a    0.0
5    5.0   a    0.0
6    3.0   c    NaN
7    NaN   d    2.0

对象列名不同，进行指定
In [9]: df1 = DataFrame({"lkey":["b","b","a","c","a","a","b"],"data1":range(7)})
In [10]: df2 = DataFrame({"rkey":["a","b","d"],"data2":range(3)})
In [11]: pd.merge(df1,df2,left_on="lkey",right_on="rkey")
Out[11]: 
   data1 lkey  data2 rkey
0      0    b      1    b
1      1    b      1    b
2      6    b      1    b
3      2    a      0    a
4      4    a      0    a
5      5    a      0    a

多对多的合并：产生行的笛卡尔集
In [12]: df1 = DataFrame({"key":["b","b","a","c","a","b"],"data1":range(6)})
In [13]: df2 = DataFrame({"key":["a","b","a","b","d"],"data2":range(5)})
In [14]: pd.merge(df1,df2,on="key",how="left")
Out[14]: 
    data1 key  data2
0       0   b    1.0
1       0   b    3.0
2       1   b    1.0
3       1   b    3.0
4       2   a    0.0
5       2   a    2.0
6       3   c    NaN
7       4   a    0.0
8       4   a    2.0
9       5   b    1.0
10      5   b    3.0

索引上的合并
利用left_index=True或者right_index=True
In [16]: left1 = DataFrame({"key":["a","b","a","a","b","c"],"value":range(6)})
In [17]: right1 = DataFrame({"group_val":[3.5,7]},index=["a","b"])
In [18]: pd.merge(left1,right1,left_on="key",right_index=True)
Out[18]: 
  key  value  group_val
0   a      0        3.5
2   a      2        3.5
3   a      3        3.5
1   b      1        7.0
4   b      4        7.0

对于层次化索引，需要以列表的形式指明用作合并键的多个列\

同时合并双方的索引
In [19]: left2 = DataFrame([[1,2],[3,4],[5,6]],index=["a","c","e"],columns=["Ohio","Nevada"])
In [20]: right2 = DataFrame([[7,8],[9,10],[11,12],[13,14]],
    ...: index=["b","c","d","e"],columns=["Missouri","Alabama"])
In [21]: pd.merge(left2,right2,how="outer",left_index=True,right_index=True)
Out[21]: 
   Ohio  Nevada  Missouri  Alabama
a   1.0     2.0       NaN      NaN
b   NaN     NaN       7.0      8.0
c   3.0     4.0       9.0     10.0
d   NaN     NaN      11.0     12.0
e   5.0     6.0      13.0     14.0

或使用join(other, on=None, how='left', lsuffix='', rsuffix='', sort=False)
#默认索引合并，当左右列名有重复时，需用lsuffix和rsuffix指定
In [24]: left2.join(right2)
Out[24]: 
   Ohio  Nevada  Missouri  Alabama
a   1.0     2.0       NaN      NaN
b   NaN     NaN       7.0      8.0
c   3.0     4.0       9.0     10.0
d   NaN     NaN      11.0     12.0
e   5.0     6.0      13.0     14.0

向join传入一组DataFrame
In [25]: another = DataFrame([[7,8],[9,10],[11,12],[16,17]],index=["a","c","e","f"],columns=["New York","Oregon"])
In [26]: left2.join([right2,another])
Out[26]: 
   Ohio  Nevada  Missouri  Alabama  New York  Oregon
a     1       2       NaN      NaN         7       8
c     3       4       9.0     10.0         9      10
e     5       6      13.0     14.0        11      12

轴向连接
对于numpy数组：concatenate
In [27]: arr = np.arange(12).reshape(4,3)
In [28]: np.concatenate([arr,arr],axis=1)
Out[28]: 
array([[ 0,  1,  2,  0,  1,  2],
       [ 3,  4,  5,  3,  4,  5],
       [ 6,  7,  8,  6,  7,  8],
[ 9, 10, 11,  9, 10, 11]])

对于pandas对象：concat函数
concat(objs, axis=0, join='outer', join_axes=None, ignore_index=False, keys=None, levels=None, names=None, verify_integrity=False, copy=True)

join : {'inner', 'outer'}, default 'outer'
join_axes：list of Index objects。指明使用的索引
keys：与连接对象有关的值，形成层次化索引；应用于axis=1，成为列头
names：用于创建分层级别的名称
ignore_index：不保留连接轴上的索引，产生一组新索引

In [31]: s1 = Series([0,1],index=["a","b"])
In [32]: s2 = Series([2,3,4],index=["c","d","e"])
In [33]: s3 = Series([5,6],index=["f","g"])
In [34]: pd.concat([s1,s2,s3])
Out[34]: 
a    0
b    1
c    2
d    3
e    4
f    5
g    6
#concat默认在axis=0上工作，产生一个新的Series；如果传入axis=1，变成一个DataFrame（列数为传入obj的长度）

In [35]: pd.concat([s1,s2,s3],axis=1)
Out[35]: 
     0    1    2
a  0.0  NaN  NaN
b  1.0  NaN  NaN
c  NaN  2.0  NaN
d  NaN  3.0  NaN
e  NaN  4.0  NaN
f  NaN  NaN  5.0
g  NaN  NaN  6.0

通过join_axes指定其他轴上使用的索引
In [29]: pd.concat([s1,s4],axis=1,join_axes=[["a","c","b","e"]])
Out[29]:
     0    1
a  0.0  0.0
c  NaN  NaN
b  1.0  5.0
e  NaN  NaN
 
创建层次化索引
In [30]: pd.concat([s1,s2,s3],keys=["one","two","three"])
Out[30]:
one    a    0
       b    1
two    c    2
       d    3
       e    4
three  f    5
       g    6
dtype: int64

In [42]: pd.concat([s1,s2,s3],keys=["one","two","three"],axis=1)
Out[42]: 
   one  two  three
a  0.0  NaN    NaN
b  1.0  NaN    NaN
c  NaN  2.0    NaN
d  NaN  3.0    NaN
e  NaN  4.0    NaN
f  NaN  NaN    5.0
g  NaN  NaN    6.0

#对DataFrame同理
In [43]: df1 = DataFrame(np.arange(6).reshape(3,2),index=["a","b","c"],columns=["one","two"])
In [44]: df2 = DataFrame(5+np.arange(4).reshape(2,2),index=["a","c"],columns=["three","four"])
In [45]: pd.concat([df1,df2],axis=1,keys=["level1","level2"])
Out[45]: 
  level1     level2     
     one two  three four
a      0   1    5.0  6.0
b      2   3    NaN  NaN
c      4   5    7.0  8.0

添加层次化索引参数
In [48]: pd.concat([df1,df2],axis=1,keys=["level1","level2"],names=["upper","lower"])
Out[48]: 
upper level1     level2     
lower    one two  three four
a          0   1    5.0  6.0
b          2   3    NaN  NaN
c          4   5    7.0  8.0

合并重叠数据
基于np.where
或者combine_first()：组合Series值，优先第一个Series值，非NA值优先
In [52]: df1 = DataFrame([[1,np.nan]])
In [53]: df2 = DataFrame([[3,4]])
In [54]: df1.combine_first(df2)
Out[54]: 
   0    1
0  1  4.0

重塑和轴向旋转
重塑层次化索引
stack：列转行
unstack：行转列

In [14]: data = DataFrame(np.arange(6).reshape(2,3),
    ...: index=pd.Index(["Ohio","Colorado"],name="state"),
    ...: columns=pd.Index(["one","two","three"],name="number"))

In [15]: data
Out[15]:
number    one  two  three
state
Ohio        0    1      2
Colorado    3    4      5

In [16]: data.stack()
Out[16]:
state     number
Ohio      one       0
          two       1
          three     2
Colorado  one       3
          two       4
          three     5
dtype: int32

In [17]: data.unstack()
Out[17]:
number  state
one     Ohio        0
        Colorado    3
two     Ohio        1
        Colorado    4
three   Ohio        2
        Colorado    5
dtype: int32
#默认情况下，unstack操作的是最内层

pivot(index=None, columns=None, values=None)
#透视，列转行
#values为填充DataFrame数据列的列名
In [4]: frame = pd.DataFrame({'foo': ['one','one','one','two','two','two'],
   ...:                        'bar': ['A', 'B', 'C', 'A', 'B', 'C'],
   ...:                        'baz': [1, 2, 3, 4, 5, 6]})
In [6]: frame.pivot(index="foo",columns="bar",values="baz")
Out[6]: 
bar  A  B  C
foo         
one  1  2  3
two  4  5  6

透视表：pivot_table()
#根据一个或多个键对数据进行聚合，并根据行和列上的分组键将数据分配到各个矩形区域
pivot_table(data, values=None, index=None, columns=None, aggfunc='mean', fill_value=Non)
In [16]: tips = pd.read_csv("ch08/tips.csv")
In [17]: tips.head()
Out[17]:
   total_bill   tip     sex smoker  day    time  size
0       16.99  1.01  Female     No  Sun  Dinner     2
1       10.34  1.66    Male     No  Sun  Dinner     3
2       21.01  3.50    Male     No  Sun  Dinner     3
3       23.68  3.31    Male     No  Sun  Dinner     2
4       24.59  3.61  Female     No  Sun  Dinner     4

In [33]: tips.pivot_table(["tip","size"],index=["sex","day"],columns="smoker")
Out[33]:
                 size                 tip
smoker             No       Yes        No       Yes
sex    day
Female Fri   2.500000  2.000000  3.125000  2.682857
       Sat   2.307692  2.200000  2.724615  2.868667
       Sun   3.071429  2.500000  3.329286  3.500000
       Thur  2.480000  2.428571  2.459600  2.990000
Male   Fri   2.000000  2.125000  2.500000  2.741250
       Sat   2.656250  2.629630  3.256563  2.879259
       Sun   2.883721  2.600000  3.115349  3.521333
       Thur  2.500000  2.300000  2.941500  3.058000
 
#传入margins=True添加行和列的小计和总计
In [34]: tips.pivot_table(["tip","size"],index=["sex","day"],columns="smoker",margins=True)
Out[34]:
                 size                           tip
smoker             No       Yes       All        No       Yes       All
sex    day
Female Fri   2.500000  2.000000  2.111111  3.125000  2.682857  2.781111
       Sat   2.307692  2.200000  2.250000  2.724615  2.868667  2.801786
       Sun   3.071429  2.500000  2.944444  3.329286  3.500000  3.367222
       Thur  2.480000  2.428571  2.468750  2.459600  2.990000  2.575625
Male   Fri   2.000000  2.125000  2.100000  2.500000  2.741250  2.693000
       Sat   2.656250  2.629630  2.644068  3.256563  2.879259  3.083898
       Sun   2.883721  2.600000  2.810345  3.115349  3.521333  3.220345
       Thur  2.500000  2.300000  2.433333  2.941500  3.058000  2.980333
All          2.668874  2.408602  2.569672  2.991854  3.008710  2.998279
 
#传入其它函数
In [35]: tips.pivot_table("tip",index=["sex","day"],columns="smoker",aggfunc="count",margins=True)
Out[35]:
smoker        No  Yes  All
sex    day
Female Fri     2    7    9
       Sat    13   15   28
       Sun    14    4   18
       Thur   25    7   32
Male   Fri     2    8   10
       Sat    32   27   59
       Sun    43   15   58
       Thur   20   10   30
All          151   93  244
 
melt(frame, id_vars=None, value_vars=None, var_name=None, value_name='value', col_level=None)
#逆透视
In [26]: df = pd.DataFrame({'A': {0: 'a', 1: 'b', 2: 'c'},
    ...:                     'B': {0: 1, 1: 3, 2: 5},
    ...:                     'C': {0: 2, 1: 4, 2: 6}})
    ...:

In [27]: pd.melt(df, id_vars=['A'], value_vars=['B', 'C'])
Out[27]:
   A variable  value
0  a        B      1
1  b        B      3
2  c        B      5
3  a        C      2
4  b        C      4
5  c        C      6

In [28]: pd.melt(df, id_vars=['A'], value_vars=['B'],
    ...:         var_name='myVarname', value_name='myValname')
    ...:
Out[28]:
   A myVarname  myValname
0  a         B          1
1  b         B          3
2  c         B          5 

交叉表：crosstab
#计算分组频率的特殊透视表
crosstab(index, columns, values=None, rownames=None, colnames=None, aggfunc=None, margins=False, margins_name='All', dropna=True, normalize=False)

In [36]: pd.crosstab([tips.time,tips.day],tips.smoker,margins=True)
Out[36]:
smoker        No  Yes  All
time   day
Dinner Fri     3    9   12
       Sat    45   42   87
       Sun    57   19   76
       Thur    1    0    1
Lunch  Fri     1    6    7
       Thur   44   17   61
All          151   93  244
 
#也可以使用pivot_table，但是不如crosstab方便

数据转化
移除重复数据
利用duplicated()返回布尔型Series
利用drop_duplicates()
In [36]: data = DataFrame({"k1":["one"]*3+["two"]*4,"k2":[1,1,2,3,3,4,4]})
In [40]: data.drop_duplicates()
Out[40]: 
    k1  k2
0  one   1
2  one   2
3  two   3
5  two   4
指定部分列进行判断，保留第一个出现的值组合
In [41]: data.drop_duplicates(["k1"])
Out[41]: 
    k1  k2
0  one   1
3  two   3

利用函数或映射进行数据转换
基于Series的map
In [42]: data = DataFrame({"food":["bacon","pulled pork","bacon","Pastrami","corned beef","Bacon","pastrami","honey ham","nova lox"],
...: "ounces":[4,3,12,6,7.5,8,3,5,6]})
In [44]: meat2animal = {"bacon":"pig","pulled pork":"pig","pastrami":"cow","corned beef":"cow","honey ham":"pig","nova lox":"salmon"}
In [45]: data["animal"] = data["food"].map(str.lower).map(meat2animal)
或者
In [48]: data["food"].map(lambda x: meat2animal[x.lower()])
Out[48]: 
0       pig
1       pig
2       pig
3       cow
4       cow
5       pig
6       cow
7       pig
8    salmon

替换值
data.replace([-999,-1000],np.nan)
data.replace([-999,-1000],[np.nan,0])

重命名轴索引
利用rename
In [49]: data = DataFrame(np.arange(12).reshape(3,4),index=["Ohio","Colorado","New York"],columns=["one","two","three","four"])
In [51]: data.rename(index=str.title,columns=str.upper)
Out[51]: 
          ONE  TWO  THREE  FOUR
Ohio        0    1      2     3
Colorado    4    5      6     7
New York    8    9     10    11
rename结合字典型对象实现对部分轴标签的更新
In [52]: data.rename(index={"Ohio":"Indiana"},columns={"three":"peekaboo"})
Out[52]: 
          one  two  peekaboo  four
Indiana     0    1         2     3
Colorado    4    5         6     7
New York    8    9        10    11

离散化和面元划分
将人员数据划分为不同年龄组
In [53]: ages = [20,22,25,27,21,23,27,31,61,45,41,32]
In [54]: bins = [18,25,35,60,100]
设置右区间为开
In [60]: pd.cut(ages,bins,right=False)
Out[60]: 
[[18, 25), [18, 25), [25, 35), [25, 35), [18, 25), ..., [25, 35), [60, 100), [35, 60), [35, 60), [25, 35)]
Length: 12
Categories (4, interval[int64]): [[18, 25] < [25, 35] < [35, 60] < [60, 100]]
设置面元名称
In [61]: group_names = ["Youth","YoungAdult","MiddleAged","Senior"]
In [62]: pd.cut(ages,bins,labels=group_names)
Out[62]: 
[Youth, Youth, Youth, YoungAdult, Youth, ..., YoungAdult, Senior, MiddleAged, MiddleAged, YoungAdult]
Length: 12
Categories (4, object): [Youth < YoungAdult < MiddleAged < Senior]

qcut(data,4)：可以将样本按四分位数等分

检测和过滤异常值
利用布尔型DataFrame和any方法
In [64]: data = DataFrame(np.random.randn(1000,4))
In [65]: data[(np.abs(data)>3).any(1)]
Out[65]: 
            0         1         2         3
5   -0.539741  0.476985  3.248944 -1.021228
97  -0.774363  0.552936  0.106061  3.927528
102 -0.655054 -0.565230  3.176873  0.959533
305 -2.315555  0.457246 -0.025907 -3.399312
324  0.050188  1.951312  3.260383  0.963301
400  0.146326  0.508391 -0.196713 -3.745356
499 -0.293333 -0.242459 -3.056990  1.918403
523 -3.428254 -0.296336 -0.439938 -0.867165
586  0.275144  1.179227 -3.184377  1.369891
808 -0.362528 -3.548824  1.553205 -2.186301
900  3.366626 -2.372214  0.851010  1.332846

排列和随机采样
In [66]: frame = DataFrame(np.arange(5*4).reshape(5,4))
利用np.random.permutation：随机重排列
In [67]: sample = np.random.permutation(5)
In [68]: sample
Out[68]: array([1, 0, 2, 3, 4])

In [69]: frame.take(sample)
Out[69]: 
    0   1   2   3
1   4   5   6   7
0   0   1   2   3
2   8   9  10  11
3  12  13  14  15
4  16  17  18  19
