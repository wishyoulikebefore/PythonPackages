读取文本格式的数据
read_table(sep=”\t”)
read_csv(sep=”,”)    
         
参数：
path：文件系统位置
sep或delimiter：对各字段进行拆分的字符序列或正则表达式
header：用作列名的行号，默认第一行；不然需要指定None
index_col：用作行索引的列编号或列名
names：自定义列名，结合header=None
skiprows：需要忽略的行数
na_values：用于替换NA的值
parse_dates：尝试将数据解析为日期
nrows：从头开始，需要读取的行数
chunksize：文件块的大小（用于迭代）
skip_footer：从文件末尾开始，需要忽略的行数
dtype：设定某列数据的属性，节约内存，如dtype={"user_id": int, "username": object}

In [3]: pd.read_csv("ex2.csv",header=None)
Out[3]:
   0   1   2   3      4
0  1   2   3   4  hello
1  5   6   7   8  world
2  9  10  11  12    foo

自定义列名
In [4]: pd.read_csv("ex2.csv",names=["a","b","c","d","message"])

将message列做成索引
In [5]: pd.read_csv("ex2.csv",names=["a","b","c","d","message"],index_col="message")

层次化索引
In [7]: pd.read_csv("csv_mindex.csv",index_col=["key1","key2"])
Out[7]:
           value1  value2
key1 key2
one  a          1       2
     b          3       4
     c          5       6
     d          7       8
two  a          9      10
     b         11      12
     c         13      14
     d         15      16

正则表示分隔符
In [8]: pd.read_table("ex3.txt",sep="\s+")
Out[8]:
            A         B         C
aaa -0.264438 -1.026059 -0.619500
bbb  0.927272  0.302904 -0.032399
ccc -0.264273 -0.386314 -0.217601
ddd -0.871858 -0.348382  1.100491
#由于列名比数据行的数量少，因此read_table推断第一列为索引

指定NA标记值
In [11]: pd.read_csv("ex5.csv",na_values={"message":["foo","NA"],"something":["two"]})
Out[11]:
  something  a   b     c   d message
0       one  1   2   3.0   4     NaN
1       NaN  5   6   NaN   8   world
2     three  9  10  11.0  12     NaN

读取大文件
利用chunksize：指定每次读取的行数
In [138]: reader = pd.read_table('tmp.sv', sep='|', chunksize=1000)
In [139]: reader
Out[139]: <pandas.io.parsers.TextFileReader at 0x120d2f290>

In [140]: for chunk in reader:
   .....:     print(chunk)

指定iterator=True 也可以返回一个可迭代对象TextFileReader 
In [141]: reader = pd.read_table('tmp.sv', sep='|', iterator=True)
In [142]: reader.get_chunk(5)

reader = pd.read_csv(f, sep=',', iterator=True)
loop = True
chunkSize = 100000
chunks = []
while loop:
    try:
        chunk = reader.get_chunk(chunkSize)
        chunks.append(chunk)
    except StopIteration:
        loop = False
        print("Iteration is stopped.")
df = pd.concat(chunks, ignore_index=True)
或者利用paratext模块(需要SWIG支持)
加载csv文件
df = paratext.load_csv_to_pandas("hepatitis.csv")

列迭代器
paratext.load_csv_as_iterator(filename,expand=True,forget=True)
#expand关键字强制ParaText使用字符串来表示类别，而不是使用整型
#forget可以让迭代器去释放已经被解析器访问过的列数据所占据的空间

加载入dict
dict_frame, levels = paratext.load_csv_to_dict(filename)
#dict_frame:maps column names to column data
#levels:contains a list of level strings for each categorical column


将数据输出到文本格式
to_csv(path=None, sep=',', na_rep='', columns=None, header=True, index=True, index_label=None)
#header：布尔值或字符串列表，default=True，输出列名

读取Excel文件（需要xlrd和openpyxl）
#便于从单个excel文件中读取或输出多个表格
读取excel
read_excel(io, sheetname=0, header=0, skiprows=None, index_col=None, names=None, parse_cols=None, date_parser=None, na_values=None)
写入excel
to_excel(excel_writer, sheet_name='Sheet1', na_rep='', columns=None, header=True, index=True, index_label=None, startrow=0, startcol=0)

