read_csv中有个参数chunksize，通过指定一个chunksize分块大小来读取文件，返回的是一个可迭代的对象TextFileReader

In [138]: reader = pd.read_table('tmp.sv', sep='|', chunksize=4)
"""chunksize指定每次读取的行数"""

In [139]: reader
Out[139]: <pandas.io.parsers.TextFileReader at 0x120d2f290>

In [140]: for chunk in reader:
   .....:     print(chunk)
   
指定iterator=True 也可以返回一个可迭代对象TextFileReader 
In [141]: reader = pd.read_table('tmp.sv', sep='|', iterator=True)

In [142]: reader.get_chunk(5)

reader = pd.read_csv(f, sep=',', iterator=True)
loop = True
chunkSize = 100000
chunks = []
while loop:
    try:
        chunk = reader.get_chunk(chunkSize)
        chunks.append(chunk)
    except StopIteration:
        loop = False
        print("Iteration is stopped.")
df = pd.concat(chunks, ignore_index=True)

或者利用paratext模块(速度可以是2.5G/s)
加载csv文件
df = paratext.load_csv_to_pandas("hepatitis.csv")

列迭代器
paratext.load_csv_as_iterator(filename,expand=True,forget=True)
#expand关键字强制ParaText使用字符串来表示类别，而不是使用整型
#forget可以让迭代器去释放已经被解析器访问过的列数据所占据的空间

加载入dict
dict_frame, levels = paratext.load_csv_to_dict(filename)
#dict_frame:maps column names to column data
#levels:contains a list of level strings for each categorical column
